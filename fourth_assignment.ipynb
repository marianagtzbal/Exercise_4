{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*This assignment was done by group of ID*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<9>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<Tuesday>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This assignment is based on the Tensor class. Your task is to train the MLP to perform classification on Fashion MNIST dataset. Your task is to perform hyperparameter search to look for the best hyperparameters for this specific task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Important* - Rembmer that you should not use test set to fine-tune your parameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, you should apply both Grid Search and Random Search to illustrate the differences in their results. To ensure a fair comparison, the total number of model evaluations should be equal for both Grid Search and Random Search. \n",
    "Be sure to present your findings for both scenarios: using a simple train-validation split and employing cross-validation.\n",
    "Additionally, you are encouraged to experiment with any other hyperparameter optimization techniques you are familiar with. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to find the best hyperparameters in space of:\n",
    "\n",
    "(1) Batch Size\n",
    "\n",
    "(2) Learning Rate\n",
    "\n",
    "(3) Number of Epochs\n",
    "\n",
    "(4) Activation Functions (here you need to modify MLP Class)\n",
    "\n",
    "(5) Architectures (Different number of layers, different number of neurons per layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from typing import List\n",
    "from Tensor import Tensor\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP Class - here add possibility for using ReLU as a activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP:\n",
    "    def __init__(self, n_in: int, n_out: int, hidden_dims: list, activation_func:str):\n",
    "        sizes = [n_in] + hidden_dims + [n_out]\n",
    "        self.layers = []\n",
    "        self.activation_func=activation_func\n",
    "        \n",
    "        for i in range(len(sizes)-1):\n",
    "            layer = Tensor(shape=(sizes[i+1], sizes[i]), label=f'layer {i}')\n",
    "            layer.data = np.random.uniform(low=-0.05, high=0.05, size=(sizes[i+1], sizes[i]))\n",
    "            self.layers.append(layer)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        for idx, layer in enumerate(self.layers): \n",
    "            x = layer @ x\n",
    "            if idx < len(self.layers) - 1:\n",
    "                if self.activation_func==\"relu\":\n",
    "                    x = x.relu()\n",
    "                else: \n",
    "                    x = x.tanh()\n",
    "        return x\n",
    "    \n",
    "    def parameters(self):\n",
    "        return self.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST_Net class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_Net:\n",
    "    def __init__(self, hidden_dims=[64],activation_func=\"tanh\"):\n",
    "        self.mlp = MLP(n_in=784, n_out=10, hidden_dims=hidden_dims,activation_func=activation_func)\n",
    "    def __call__(self, x):\n",
    "        return self.mlp(x).softmax()\n",
    "    def parameters(self):\n",
    "        return self.mlp.parameters()\n",
    "    \n",
    "model = MNIST_Net(activation_func=\"tanh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validate auxilary function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, X_set, Y_set):\n",
    "    \"\"\"\n",
    "    Evaluate the accuracy of the model on a given dataset.\n",
    "\n",
    "    This function performs a forward pass on each sample in the dataset,\n",
    "    predicts the class, and compares it to the true class to calculate\n",
    "    the overall accuracy.\n",
    "    \"\"\"\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    \n",
    "    for i in range(X_set.shape[0]):\n",
    "        x = X_set[i]\n",
    "        y_true = Y_set[i]\n",
    "        \n",
    "        # Forward pass\n",
    "        y_pred = model(x)\n",
    "        \n",
    "        # Get the predicted class (assuming y_pred is a Tensor with probabilities)\n",
    "        predicted_class = np.argmax(y_pred.data)\n",
    "        \n",
    "        # Check if the prediction is correct\n",
    "        if predicted_class == y_true:\n",
    "            correct_predictions += 1\n",
    "        \n",
    "        total_predictions += 1\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fashion MNIST Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,)\n"
     ]
    }
   ],
   "source": [
    "# Load Fashion MNIST\n",
    "fashion_mnist = fetch_openml('Fashion-MNIST', version=1)\n",
    "images, labels = fashion_mnist.data, fashion_mnist.target\n",
    "\n",
    "images = images.values.reshape(-1, 28, 28)\n",
    "labels = labels.values\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, train_size=60000, test_size=10000, stratify=labels, random_state=42)\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how the datapoints look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(3, 3, figsize=(10, 10))\n",
    "for i in range(9):\n",
    "    ax = axs[i//3, i%3]\n",
    "    ax.imshow(X_train[i].reshape(28, 28), cmap='gray')\n",
    "    ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the input data:\n",
    "X_train = X_train.astype('float32').reshape(-1, 784)\n",
    "X_test = X_test.astype('float32').reshape(-1, 784)\n",
    "y_train = y_train.astype('int64')\n",
    "y_test = y_test.astype('int64')\n",
    "X_train /= 255.0\n",
    "X_test /= 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TRAIN-VAL-TEST**\n",
    "\n",
    " In this section, we will search for hyperparameters by splitting the data into a training set (50,000 samples) and a validation set (10,000 samples). We will conduct the hyperparameter search using both Grid Search and Random Search methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, train_size=50000, test_size=10000, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auxilary function to estimate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(batch_size:int=32, num_epochs:int=50, lr:float=0.001,\n",
    "                       hidden_dims:List[int]=[64], activation_func:str=\"tanh\",test_evaluation:bool=False):\n",
    "    \"\"\"\n",
    "    Train a neural network model and evaluate its performance on a validation set.\n",
    "\n",
    "    This function trains the `MNIST_Net` model using the given hyperparameters, including\n",
    "    batch size, number of epochs, learning rate, and hidden layer dimensions. It shuffles\n",
    "    the training data at the start of each epoch and performs a forward and backward pass\n",
    "    to update the model weights. The function then evaluates the model on a validation set\n",
    "    and optionally on a test set.\n",
    "    \"\"\"\n",
    "    model = MNIST_Net(hidden_dims,activation_func)\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        indices = np.arange(X_train.shape[0])\n",
    "        np.random.shuffle(indices)\n",
    "        X_shuffled = X_train[indices]\n",
    "        y_shuffled = y_train[indices]\n",
    "        \n",
    "        for i in range(0, X_shuffled.shape[0], batch_size):\n",
    "            X_batch = X_shuffled[i:i + batch_size]\n",
    "            y_batch = y_shuffled[i:i + batch_size]\n",
    "            \n",
    "            # Convert entire batch to flattened Tensors\n",
    "            X_tensors = [Tensor(data=x.flatten()) for x in X_batch]\n",
    "            preds = [model(x) for x in X_tensors]\n",
    "            \n",
    "            # Compute loss for the batch\n",
    "            mb_loss = sum([ypred.cross_entropy(ytrue) for ytrue, ypred in zip(y_batch, preds)]) / batch_size\n",
    "            \n",
    "            # Zero gradients\n",
    "            for p in model.parameters():\n",
    "                p.grad = np.zeros_like(p.grad)\n",
    "            \n",
    "            # Backward pass\n",
    "            mb_loss.backward()\n",
    "            \n",
    "            # Update weights\n",
    "            for p in model.parameters():\n",
    "                p.data -= lr * p.grad\n",
    "\n",
    "    # Calculate validation accuracy\n",
    "    validation_accuracy = validate(model, X_val, y_val)\n",
    "\n",
    "    # Calculate test set accuracy\n",
    "    if test_evaluation:\n",
    "        test_accuracy = validate(model, X_test, y_test)\n",
    "        return validation_accuracy, test_accuracy\n",
    "    else:\n",
    "        return validation_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the exemplary trainig..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training: test accuracy: 0.1007\n",
      "Validation accuracy: 0.8204\n"
     ]
    }
   ],
   "source": [
    "model = MNIST_Net(activation_func=\"tanh\")\n",
    "\n",
    "val_acc = validate(model, X_test, y_test)\n",
    "print(f\"Before training: test accuracy: {val_acc}\")\n",
    "\n",
    "# Parameters\n",
    "batch_size = 64\n",
    "num_epochs = 1\n",
    "lr = 0.5\n",
    "\n",
    "val_acc = train_and_evaluate(batch_size, num_epochs, lr)\n",
    "print(f\"Validation accuracy: {val_acc}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*GRID SEARCH*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add here more possibilities\n",
    "hyperparameter_space = {\n",
    "    'batch_size': [256, 128],\n",
    "    'num_epochs': [10,20,30],\n",
    "    'lr': [0.01, 0.1, 0.001],\n",
    "    'hidden_dims': [[64], [128, 64], [64, 64, 64]],\n",
    "    'activation_func': [\"relu\",\"tanh\"]\n",
    "}\n",
    "\n",
    "\n",
    "all_combinations_grid_search = list(product(\n",
    "    hyperparameter_space['batch_size'],\n",
    "    hyperparameter_space['num_epochs'],\n",
    "    hyperparameter_space['lr'],\n",
    "    hyperparameter_space['hidden_dims'],\n",
    "    hyperparameter_space['activation_func'],\n",
    "))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current best configuration (256, 10, 0.01, [64], 'relu'), with the Val-Accuracy: 0.7667\n",
      "Current best configuration (256, 10, 0.1, [64], 'relu'), with the Val-Accuracy: 0.8536\n",
      "Current best configuration (256, 10, 0.1, [64], 'tanh'), with the Val-Accuracy: 0.856\n",
      "Current best configuration (256, 10, 0.1, [128, 64], 'relu'), with the Val-Accuracy: 0.8572\n",
      "Current best configuration (256, 20, 0.1, [64], 'relu'), with the Val-Accuracy: 0.8717\n",
      "Current best configuration (256, 20, 0.1, [64], 'tanh'), with the Val-Accuracy: 0.8725\n",
      "Current best configuration (256, 20, 0.1, [64, 64, 64], 'relu'), with the Val-Accuracy: 0.8729\n"
     ]
    }
   ],
   "source": [
    "best_accuracy = 0\n",
    "for batch_size, num_epochs, lr, hidden_size,activation_func in all_combinations_grid_search:\n",
    "    accuracy = train_and_evaluate(batch_size, num_epochs, lr, hidden_size,activation_func)    \n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_hyperparameters = (batch_size, num_epochs, lr, hidden_size,activation_func)\n",
    "        print(f\"Current best configuration {best_hyperparameters}, with the Val-Accuracy: {best_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After finding the best hyperparameters we evaluate them on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_batch_size, best_num_epochs, best_lr, best_hidden_size,activation_func = best_hyperparameters\n",
    "grid_search_train_val_validation, grid_search_train_val_test = train_and_evaluate(best_batch_size, best_num_epochs, best_lr, best_hidden_size, activation_func,True)\n",
    "print(f\"Final Validation Accuracy: {round(grid_search_train_val_validation, 3)}\")\n",
    "print(f\"Final Test Accuracy: {round(grid_search_train_val_test, 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TRAIN VAL TEST - Random Search**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import random\n",
    "# Expand the hyperparameter space with additional options if needed.\n",
    "# Implement a similar approach for random search, where hyperparameters are sampled randomly.\n",
    "# Note: The hyperparameter space for random search can be larger compared to grid search, \n",
    "# as you are not limited to predefined discrete values.\n",
    "# However, to ensure a fair comparison between grid search and random search,\n",
    "# make sure to evaluate the model the same number of times in both methods.\n",
    "\n",
    "\n",
    "\n",
    "hyperparameter_space_random_search = {\n",
    "    'batch_size': [256, 128],\n",
    "    'num_epochs': [10,20,30],\n",
    "    'lr': [0.01, 0.1, 0.001],\n",
    "    'hidden_dims': [[64], [128, 64], [64, 64, 64]],\n",
    "    'activation_func': [\"relu\",\"tanh\"]\n",
    "}\n",
    "\n",
    "def sample(hsrsearch):\n",
    "    batch_size= random.choice(hsrsearch[\"batch_size\"])\n",
    "    num_epochs=random.choice(hsrsearch[\"num_epochs\"])\n",
    "    lr=random.choice(hsrsearch[\"lr\"])\n",
    "    hidden_dims=random.choice(hsrsearch[\"hidden_dims\"])\n",
    "    activation_func=random.choice(hsrsearch[\"activation_func\"])\n",
    "    \n",
    "    return batch_size, num_epochs,lr,hidden_dims,activation_func\n",
    "\n",
    "\n",
    "best_accuracy = 0\n",
    "for _ in range(len(all_combinations_grid_search)):\n",
    "    sampled_hyperparameters = sample(hyperparameter_space_random_search)\n",
    "    batch_size, num_epochs, lr, hidden_size, activation_func= sampled_hyperparameters\n",
    "    accuracy = train_and_evaluate(batch_size, num_epochs, lr, hidden_size ,activation_func)    \n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_hyperparameters = (batch_size, num_epochs, lr, hidden_size,activation_func) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After finding the best hyperparameters with random search we evalute them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_batch_size, best_num_epochs, best_lr, best_hidden_size = best_hyperparameters\n",
    "random_search_train_val_validation, random_search_train_val_test = train_and_evaluate(best_batch_size, best_num_epochs, best_lr, best_hidden_size, True)\n",
    "print(f\"Final Validation Accuracy: {round(grid_search_train_val_validation, 3)}\")\n",
    "print(f\"Final Test Accuracy: {round(random_search_train_val_test, 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cross-Validation**\n",
    "\n",
    "In this section, we will perform hyperparameter tuning using cross-validation. We will explore both Grid Search and Random Search methods. To ensure a fair comparison, make sure to evaluate your model the same number of times as in previous searches. Keep in mind that cross-validation involves training and evaluating the model multiple times for each set of hyperparameters, which provides a more robust estimate of model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load data once more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, train_size=60000, test_size=10000, stratify=labels, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auxilary function for model estimation with cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete this function. \n",
    "\n",
    "def split_data_into_folds(folds):\n",
    "    kf=[]\n",
    "    partitions={}\n",
    "    size = len(X_train)\n",
    "    start_idx=0\n",
    "    for fold in range(folds):\n",
    "        partitions[fold]=range(int(start_idx),int(start_idx+size/folds))\n",
    "        start_idx+=size/folds\n",
    "\n",
    "    val_idx=[]\n",
    "    train_idx=[]\n",
    "    for fold in range(folds):\n",
    "        val_idx= partitions[fold]\n",
    "        train_idx= np.setdiff1d(range(size), val_idx) \n",
    "        kf.append([train_idx,val_idx])\n",
    "        val_idx=[]\n",
    "        train_idx=[]\n",
    "\n",
    "    return kf\n",
    "\n",
    "def train_and_evaluate_cv(batch_size: int = 32, num_epochs: int = 50, lr: float = 0.001,\n",
    "                       hidden_dims: List[int] = [64], folds: int = 5, activation_func:str=\"tanh\",test_evaluation: bool = False):\n",
    "    \n",
    "    # Initialize K-Fold cross-validation\n",
    "    validation_accuracies = []\n",
    "    \n",
    "    kf = split_data_into_folds(folds) # funciton that generates indicies of belonging to specific fold\n",
    "   \n",
    "    # Cross-validation loop\n",
    "    for train_index, val_index in kf:\n",
    "        X_fold_train, X_fold_val = X_train[train_index], X_train[val_index]\n",
    "        y_fold_train, y_fold_val = y_train[train_index], y_train[val_index]\n",
    "        \n",
    "        # Initialize the model for each fold\n",
    "        model = MNIST_Net(hidden_dims,activation_func)\n",
    "        \n",
    "        # Training loop\n",
    "        for epoch in range(num_epochs):\n",
    "            indices = np.arange(X_fold_train.shape[0])\n",
    "            np.random.shuffle(indices)\n",
    "            X_shuffled = X_fold_train[indices]\n",
    "            y_shuffled = y_fold_train[indices]\n",
    "            \n",
    "            for i in range(0, X_shuffled.shape[0], batch_size):\n",
    "                X_batch = X_shuffled[i:i + batch_size]\n",
    "                y_batch = y_shuffled[i:i + batch_size]\n",
    "                \n",
    "                # Convert entire batch to flattened Tensors\n",
    "                X_tensors = [Tensor(data=x.flatten()) for x in X_batch]\n",
    "                preds = [model(x) for x in X_tensors]\n",
    "                \n",
    "                # Compute loss for the batch\n",
    "                mb_loss = sum([ypred.cross_entropy(ytrue) for ytrue, ypred in zip(y_batch, preds)]) / batch_size\n",
    "                \n",
    "                # Zero gradients\n",
    "                for p in model.parameters():\n",
    "                    p.grad = np.zeros_like(p.grad)\n",
    "                \n",
    "                # Backward pass\n",
    "                mb_loss.backward()\n",
    "                \n",
    "                # Update weights\n",
    "                for p in model.parameters():\n",
    "                    p.data -= lr * p.grad\n",
    "        \n",
    "        # Calculate validation accuracy for this fold\n",
    "        validation_accuracy = validate(model, X_fold_val, y_fold_val)\n",
    "        validation_accuracies.append(validation_accuracy)\n",
    "    \n",
    "    # Compute the average validation accuracy across all folds\n",
    "    avg_validation_accuracy = np.mean(validation_accuracies)\n",
    "\n",
    "    # Calculate test set accuracy if required\n",
    "    if test_evaluation:\n",
    "        test_accuracy = validate(model, X_test, y_test)\n",
    "        return avg_validation_accuracy, test_accuracy\n",
    "    else:\n",
    "        return avg_validation_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperparameter search space. Note: it should be smaller than the one used in the train-val-test example.\n",
    "# To ensure a fair comparison, each technique should evaluate the exact same number of models.\n",
    "hyperparameter_space = {\n",
    "    'batch_size': [128,64],\n",
    "    'num_epochs': [10,30],\n",
    "    'lr': [0.01,0.001],\n",
    "    'hidden_dims': [[64],[64,128]],\n",
    "    'activation_func':['relu','tanh']\n",
    "}\n",
    "\n",
    "all_combinations_grid_search_cv = list(product(\n",
    "    hyperparameter_space['batch_size'],\n",
    "    hyperparameter_space['num_epochs'],\n",
    "    hyperparameter_space['lr'],\n",
    "    hyperparameter_space['hidden_dims'],\n",
    "    hyperparameter_space['']\n",
    "))\n",
    "\n",
    "best_accuracy = 0\n",
    "folds = 5\n",
    "for batch_size, num_epochs, lr, hidden_size in all_combinations_grid_search_cv:\n",
    "    accuracy = train_and_evaluate_cv(batch_size, num_epochs, lr, hidden_size,folds)    \n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_hyperparameters = (batch_size, num_epochs, lr, hidden_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After identifying the optimal hyperparameters through a grid search with cross-validation, we evaluate their performance on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_batch_size, best_num_epochs, best_lr, best_hidden_size = best_hyperparameters\n",
    "grid_search_cv_validation, grid_search_cv_test = estimate_model_and_evaluate(best_hyperparameters, test_evaluation=True)\n",
    "print(f\"Final Validation Accuracy: {round(grid_search_cv_validation, 3)}\")\n",
    "print(f\"Final Test Accuracy: {round(grid_search_cv_test, 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter search space. Remember that it should be smaller than one used in the train-val-test example. \n",
    "# For a fair comparison we should estimate by each technique exactly the same number of models. \n",
    "hyperparameter_space_random_search = {\n",
    "    'batch_size': [128,64],\n",
    "    'num_epochs': [10,30],\n",
    "    'lr': [0.01,0.001],\n",
    "    'hidden_dims': [[64],[64,128]],\n",
    "    'activation_func':['relu','tanh']\n",
    "}\n",
    "\n",
    "best_accuracy = 0\n",
    "for _ in range(len(all_combinations_grid_search)):\n",
    "    sampled_hyperparameters = sample(hyperparameter_space_random_search)\n",
    "    batch_size, num_epochs, lr, hidden_size = sampled_hyperparameters\n",
    "    accuracy = train_and_evaluate_cv(batch_size, num_epochs, lr, hidden_size)    \n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_hyperparameters = (batch_size, num_epochs, lr, hidden_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After identifying the optimal hyperparameters through a random search with cross-validation, we evaluate their performance on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_batch_size, best_num_epochs, best_lr, best_hidden_size = best_hyperparameters\n",
    "random_search_cv_validation, random_search_cv_test = estimate_model_and_evaluate(best_hyperparameters, test_evaluation=True)\n",
    "print(f\"Final Validation Accuracy: {round(random_search_cv_validation, 3)}\")\n",
    "print(f\"Final Test Accuracy: {round(random_search_cv_test, 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another hyperparameter optimization technique (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maybe later\n",
    "optional_test = 0.89\n",
    "print(f\"Final Test Accuracy: {round(optional_test, 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary of all our results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_train_val_test = 0.15\n",
    "random_search_train_val_test = 0.25\n",
    "grid_search_cv_test = 0.35\n",
    "random_search_cv_test = 0.45\n",
    "optional_test = 0.4\n",
    "\n",
    "\n",
    "# Data for the bar plot\n",
    "labels = ['Grid Search (Train+Val)', 'Random Search (Train+Val)', \n",
    "          'Grid Search (CV Test)', 'Random Search (CV Test)', 'Optional Test']\n",
    "values = [\n",
    "        grid_search_train_val_test,\n",
    "          random_search_train_val_test,\n",
    "          grid_search_cv_test,\n",
    "          random_search_cv_test,\n",
    "          optional_test\n",
    "          ]\n",
    "\n",
    "# Create the bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(labels, values, color='skyblue')\n",
    "plt.xlabel('Search Methods and Test Types', fontsize=12)\n",
    "plt.ylabel('Accuracy', fontsize=12)\n",
    "plt.title('Comparison of Search Methods and Test Accuracies', fontsize=14)\n",
    "plt.xticks(rotation=30, ha='right', fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning_updated",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
